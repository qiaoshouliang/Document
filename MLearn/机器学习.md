# 机器学习分类

- 有数据和有标签的监督学习（SUPERVISED LEARNING）
- 没有数据和没有标签的非监督学习（UNSUPERVISED LEARNING）
- 结合了监督学习和非监督学习的半监督学习（MENI-SUPERVISED LEARNING）
- 从经验中总结提升的强化学习（REINFORCEMENT LEARNING）
- 有适者生存，不适者淘汰的遗传学习（GENETIC ALGORITHM）



# HBase

HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的[分布式存储系统](https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F)”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。



# 机器学习中选择特征的原则

- 避免无意义的信息

- 避免重复性的信息

- 避免复杂的信息

  ​

# 过拟合

## [过于自负](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-05-overfitting/#%E8%BF%87%E4%BA%8E%E8%87%AA%E8%B4%9F)

[![过拟合 (Overfitting)](https://morvanzhou.github.io/static/results/ML-intro/overfitting1.png)](https://morvanzhou.github.io/static/results/ML-intro/overfitting1.png)

在细说之前, 我们先用实际生活中的一个例子来比喻一下过拟合现象. 说白了, 就是机器学习模型于自信. 已经到了自负的阶段了. 那自负的坏处, 大家也知道, 就是在自己的小圈子里表现非凡, 不过在现实的大圈子里却往往处处碰壁. 所以在这个简介里, 我们把自负和过拟合画上等号.

## [回归分类的过拟合](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-05-overfitting/#%E5%9B%9E%E5%BD%92%E5%88%86%E7%B1%BB%E7%9A%84%E8%BF%87%E6%8B%9F%E5%90%88)

[![过拟合 (Overfitting)](https://morvanzhou.github.io/static/results/ML-intro/overfitting2.png)](https://morvanzhou.github.io/static/results/ML-intro/overfitting2.png)

机器学习模型的自负又表现在哪些方面呢. 这里是一些数据. 如果要你画一条线来描述这些数据, 大多数人都会这么画. 对, 这条线也是我们希望机器也能学出来的一条用来总结这些数据的线. 这时蓝线与数据的总误差可能是10. 可是有时候, 机器过于纠结这误差值, 他想把误差减到更小, 来完成他对这一批数据的学习使命. 所以, 他学到的可能会变成这样 . 它几乎经过了每一个数据点, 这样, 误差值会更小 . 可是误差越小就真的好吗? 看来我们的模型还是太天真了. 当我拿这个模型运用在现实中的时候, 他的自负就体现出来. 小二, 来一打现实数据 . 这时, 之前误差大的蓝线误差基本保持不变 .误差小的 红线误差值突然飙高 , 自负的红线再也骄傲不起来, 因为他不能成功的表达除了训练数据以外的其他数据. 这就叫做过拟合. Overfitting.

[![过拟合 (Overfitting)](https://morvanzhou.github.io/static/results/ML-intro/overfitting3.png)](https://morvanzhou.github.io/static/results/ML-intro/overfitting3.png)

那么在分类问题当中. 过拟合的分割线可能是这样, 小二, 再上一打数据 . 我们明显看出, 有两个黄色的数据并没有被很好的分隔开来. 这也是过拟合在作怪.好了, 既然我们时不时会遇到过拟合问题, 那解决的方法有那些呢.

## [解决方法](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-05-overfitting/#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95)

[![过拟合 (Overfitting)](https://morvanzhou.github.io/static/results/ML-intro/overfitting4.png)](https://morvanzhou.github.io/static/results/ML-intro/overfitting4.png)

方法一: 增加数据量, 大部分过拟合产生的原因是因为数据量太少了. 如果我们有成千上万的数据, 红线也会慢慢被拉直, 变得没那么扭曲 . 方法二:

[![过拟合 (Overfitting)](https://morvanzhou.github.io/static/results/ML-intro/overfitting5.png)](https://morvanzhou.github.io/static/results/ML-intro/overfitting5.png)

运用正规化. L1, l2 regularization等等, 这些方法适用于大多数的机器学习, 包括神经网络. 他们的做法大同小异, 我们简化机器学习的关键公式为 y=Wx . W为机器需要学习到的各种参数. 在过拟合中, W 的值往往变化得特别大或特别小. 为了不让W变化太大, 我们在计算误差上做些手脚. 原始的 cost 误差是这样计算, cost = 预测值-真实值的平方. 如果 W 变得太大, 我们就让 cost 也跟着变大, 变成一种惩罚机制. 所以我们把 W 自己考虑进来. 这里 abs 是绝对值. 这一种形式的 正规化, 叫做 l1 正规化. L2 正规化和 l1 类似, 只是绝对值换成了平方. 其他的l3, l4 也都是换成了立方和4次方等等. 形式类似. 用这些方法,我们就能保证让学出来的线条不会过于扭曲.

[![过拟合 (Overfitting)](https://morvanzhou.github.io/static/results/ML-intro/overfitting6.png)](https://morvanzhou.github.io/static/results/ML-intro/overfitting6.png)

还有一种专门用在神经网络的正规化的方法, 叫作 dropout. 在训练的时候, 我们随机忽略掉一些神经元和神经联结 , 是这个神经网络变得”不完整”. 用一个不完整的神经网络训练一次.

到第二次再随机忽略另一些, 变成另一个不完整的神经网络. 有了这些随机 drop 掉的规则, 我们可以想象其实每次训练的时候, 我们都让每一次预测结果都不会依赖于其中某部分特定的神经元. 像l1, l2正规化一样, 过度依赖的 W , 也就是训练参数的数值会很大, l1, l2会惩罚这些大的 参数. Dropout 的做法是从根本上让神经网络没机会过度依赖.



# 加速神经网络训练

包括以下几种模式:

- Stochastic Gradient Descent (SGD)
- Momentum
- AdaGrad
- RMSProp
- Adam

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup1.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup1.png)

越复杂的神经网络 , 越多的数据 , 我们需要在训练神经网络的过程上花费的时间也就越多. 原因很简单, 就是因为计算量太大了. 可是往往有时候为了解决复杂的问题, 复杂的结构和大数据又是不能避免的, 所以我们需要寻找一些方法, 让神经网络聪明起来, 快起来.

## [Stochastic Gradient Descent (SGD)](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/#Stochastic-Gradient-Descent-(SGD))

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup2.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup2.png)

所以, 最基础的方法就是 SGD 啦, 想像红色方块是我们要训练的 data, 如果用普通的训练方法, 就需要重复不断的把整套数据放入神经网络 NN训练, 这样消耗的计算资源会很大.

我们换一种思路, 如果把这些数据拆分成小批小批的, 然后再分批不断放入 NN 中计算, 这就是我们常说的 SGD 的正确打开方式了. 每次使用批数据, 虽然不能反映整体数据的情况, 不过却很大程度上加速了 NN 的训练过程, 而且也不会丢失太多准确率.如果运用上了 SGD, 你还是嫌训练速度慢, 那怎么办?

![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup3.png)

没问题, 事实证明, SGD 并不是最快速的训练方法, 红色的线是 SGD, 但它到达学习目标的时间是在这些方法中最长的一种. 我们还有很多其他的途径来加速训练.

## [Momentum 更新方法](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/#Momentum-%E6%9B%B4%E6%96%B0%E6%96%B9%E6%B3%95)

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup4.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup4.png)

大多数其他途径是在更新神经网络参数那一步上动动手脚. 传统的参数 W 的更新是把原始的 W 累加上一个负的学习率(learning rate) 乘以校正值 (dx). 这种方法可能会让学习过程曲折无比, 看起来像 喝醉的人回家时, 摇摇晃晃走了很多弯路.

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup5.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup5.png)

所以我们把这个人从平地上放到了一个斜坡上, 只要他往下坡的方向走一点点, 由于向下的惯性, 他不自觉地就一直往下走, 走的弯路也变少了. 这就是 Momentum 参数更新. 另外一种加速方法叫AdaGrad.

## [AdaGrad 更新方法](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/#AdaGrad-%E6%9B%B4%E6%96%B0%E6%96%B9%E6%B3%95)

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup6.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup6.png)

这种方法是在学习率上面动手脚, 使得每一个参数更新都会有自己与众不同的学习率, 他的作用和 momentum 类似, 不过不是给喝醉酒的人安排另一个下坡, 而是给他一双不好走路的鞋子, 使得他一摇晃着走路就脚疼, 鞋子成为了走弯路的阻力, 逼着他往前直着走. 他的数学形式是这样的. 接下来又有什么方法呢? 如果把下坡和不好走路的鞋子合并起来, 是不是更好呢? 没错, 这样我们就有了 RMSProp 更新方法.

## [RMSProp 更新方法](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/#RMSProp-%E6%9B%B4%E6%96%B0%E6%96%B9%E6%B3%95)

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup7.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup7.png)

有了 momentum 的惯性原则 , 加上 adagrad 的对错误方向的阻力, 我们就能合并成这样. 让 RMSProp同时具备他们两种方法的优势. 不过细心的同学们肯定看出来了, 似乎在 RMSProp 中少了些什么. 原来是我们还没把 Momentum合并完全, RMSProp 还缺少了 momentum 中的 这一部分. 所以, 我们在 Adam 方法中补上了这种想法.

## [Adam 更新方法](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/#Adam-%E6%9B%B4%E6%96%B0%E6%96%B9%E6%B3%95)

[![加速神经网络训练 (Speed Up Training)](https://morvanzhou.github.io/static/results/ML-intro/speedup8.png)](https://morvanzhou.github.io/static/results/ML-intro/speedup8.png)

计算m 时有 momentum 下坡的属性, 计算 v 时有 adagrad 阻力的属性, 然后再更新参数时 把 m 和 V 都考虑进去. 实验证明, 大多数时候, 使用 adam 都能又快又好的达到目标, 迅速收敛. 所以说, 在加速神经网络训练的时候, 一个下坡, 一双破鞋子, 功不可没.





